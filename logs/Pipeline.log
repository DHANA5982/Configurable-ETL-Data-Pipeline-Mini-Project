2025-10-22 17:47:45 - root - [INFO] - Logger initailised from config.
2025-10-22 17:47:45 - root - [INFO] - ----- Pipeline Execution Started -----
2025-10-22 17:47:45 - root - [INFO] - Extracting Data...
2025-10-22 17:47:45 - root - [INFO] - Reading CSV file: ../data/sales.csv
2025-10-22 17:47:45 - root - [INFO] - Reading JSON file: ../data/products.json
2025-10-22 17:47:45 - root - [INFO] - Reading PARQUET file: ../data/region.parquet
2025-10-22 17:47:45 - root - [INFO] - Merging datasets...
2025-10-22 17:47:45 - root - [INFO] - Merge complete. Dataframe shape: (23, 5)
2025-10-22 17:47:45 - root - [INFO] - Loading Data...
2025-10-22 17:47:45 - root - [INFO] - Data saved: ../data/merged_data.csv
2025-10-22 17:47:45 - root - [INFO] - Connecting to DB: postgresql+psycopg2://postgres:admin@localhost:5432/merged_data_db
2025-10-22 17:47:45 - root - [INFO] - Data successfully loaded into: merged_table
2025-10-22 17:47:45 - root - [INFO] - ----- Pipeline Execution Completed -----
2025-10-22 17:51:36 - root - [INFO] - Logger initailised from config.
2025-10-22 17:51:36 - root - [INFO] - ----- Pipeline Execution Started -----
2025-10-22 17:51:36 - root - [INFO] - Overriding config values: {'output_file': '../data/merged_data.parquet', 'output_format': 'parquet'}
2025-10-22 17:51:36 - root - [INFO] - Extracting Data...
2025-10-22 17:51:36 - root - [INFO] - Reading CSV file: ../data/sales.csv
2025-10-22 17:51:36 - root - [INFO] - Reading JSON file: ../data/products.json
2025-10-22 17:51:36 - root - [INFO] - Reading PARQUET file: ../data/region.parquet
2025-10-22 17:51:36 - root - [INFO] - Merging datasets...
2025-10-22 17:51:36 - root - [INFO] - Merge complete. Dataframe shape: (23, 5)
2025-10-22 17:51:36 - root - [INFO] - Loading Data...
2025-10-22 17:51:36 - root - [INFO] - Data saved: ../data/merged_data.parquet
2025-10-22 17:51:36 - root - [INFO] - Connecting to DB: postgresql+psycopg2://postgres:admin@localhost:5432/merged_data_db
2025-10-22 17:51:36 - root - [INFO] - Data successfully loaded into: merged_table
2025-10-22 17:51:36 - root - [INFO] - ----- Pipeline Execution Completed -----
2025-10-22 18:12:58 - root - [INFO] - Logger initailised from config.
2025-10-22 18:12:58 - root - [INFO] - ----- Pipeline Execution Started -----
2025-10-22 18:12:58 - root - [INFO] - Extracting Data...
2025-10-22 18:12:58 - root - [INFO] - Reading CSV file: ../data/sales.csv
2025-10-22 18:12:58 - root - [INFO] - Reading JSON file: ../data/products.json
2025-10-22 18:12:58 - root - [INFO] - Reading PARQUET file: ../data/region.parquet
2025-10-22 18:12:58 - root - [INFO] - Merging datasets...
2025-10-22 18:12:58 - root - [INFO] - Merge complete. Dataframe shape: (23, 5)
2025-10-22 18:12:58 - root - [INFO] - Loading Data...
2025-10-22 18:12:58 - root - [INFO] - Data saved: ../data/merged_data.csv
2025-10-22 18:12:58 - root - [INFO] - Connecting to DB: postgresql+psycopg2://postgres:admin@localhost:5432/merged_data_db
2025-10-22 18:12:58 - root - [INFO] - Data successfully loaded into: merged_table
2025-10-22 18:12:58 - root - [INFO] - ----- Pipeline Execution Completed -----
2025-10-23 07:59:49 - root - [INFO] - Logger initailised from config.
2025-10-23 07:59:49 - root - [INFO] - ----- Pipeline Execution Started -----
2025-10-23 07:59:49 - root - [INFO] - Extracting Data...
2025-10-23 07:59:49 - root - [INFO] - Reading CSV file: ../data/sales.csv
2025-10-23 07:59:49 - root - [INFO] - Reading JSON file: ../data/products.json
2025-10-23 07:59:49 - root - [INFO] - Reading PARQUET file: ../data/region.parquet
2025-10-23 07:59:49 - root - [INFO] - Merging datasets...
2025-10-23 07:59:49 - root - [INFO] - Merge complete. Dataframe shape: (23, 5)
2025-10-23 07:59:49 - root - [INFO] - Loading Data...
2025-10-23 07:59:49 - root - [INFO] - Data saved: ../data/merged_data.csv
2025-10-23 07:59:49 - root - [INFO] - Connecting to DB: postgresql+psycopg2://postgres:postgres@postgres:5432/merged_data_db
2025-10-23 07:59:52 - root - [ERROR] - Database load failed: (psycopg2.OperationalError) could not translate host name "postgres" to address: Name or service not known

(Background on this error at: https://sqlalche.me/e/20/e3q8)
Traceback (most recent call last):
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 143, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3301, in raw_connection
    return self.pool.connect()
           ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 447, in connect
    return _ConnectionFairy._checkout(self)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 711, in checkout
    rec = pool._do_get()
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 177, in _do_get
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 175, in _do_get
    return self._create_connection()
           ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 388, in _create_connection
    return _ConnectionRecord(self)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 673, in __init__
    self.__connect()
    ~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 899, in __connect
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 895, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\create.py", line 661, in connect
    return dialect.connect(*cargs, **cparams)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 629, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\psycopg2\__init__.py", line 135, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Name or service not known


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\src\pipeline.py", line 111, in load_to_db
    df.to_sql(db['table'], engine, if_exists='replace', index=False)
    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\util\_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\core\generic.py", line 3109, in to_sql
    return sql.to_sql(
           ~~~~~~~~~~^
        self,
        ^^^^^
    ...<8 lines>...
        method=method,
        ^^^^^^^^^^^^^^
    )
    ^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\io\sql.py", line 843, in to_sql
    with pandasSQL_builder(con, schema=schema, need_transaction=True) as pandas_sql:
         ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\io\sql.py", line 908, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\io\sql.py", line 1648, in __init__
    con = self.exit_stack.enter_context(con.connect())
                                        ~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3277, in connect
    return self._connection_cls(self)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 145, in __init__
    Connection._handle_dbapi_exception_noconnection(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        err, dialect, engine
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2440, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 143, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3301, in raw_connection
    return self.pool.connect()
           ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 447, in connect
    return _ConnectionFairy._checkout(self)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 711, in checkout
    rec = pool._do_get()
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 177, in _do_get
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 175, in _do_get
    return self._create_connection()
           ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 388, in _create_connection
    return _ConnectionRecord(self)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 673, in __init__
    self.__connect()
    ~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 899, in __connect
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 895, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\create.py", line 661, in connect
    return dialect.connect(*cargs, **cparams)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 629, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\psycopg2\__init__.py", line 135, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Name or service not known

(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-10-23 07:59:52 - root - [INFO] - ----- Pipeline Execution Completed -----
2025-10-23 08:46:44 - root - [INFO] - Logger initailised from config.
2025-10-23 08:46:44 - root - [INFO] - ----- Pipeline Execution Started -----
2025-10-23 08:46:44 - root - [INFO] - Extracting Data...
2025-10-23 08:46:44 - root - [INFO] - Reading CSV file: ../data/sales.csv
2025-10-23 08:46:44 - root - [INFO] - Reading JSON file: ../data/products.json
2025-10-23 08:46:44 - root - [INFO] - Reading PARQUET file: ../data/region.parquet
2025-10-23 08:46:44 - root - [INFO] - Merging datasets...
2025-10-23 08:46:44 - root - [INFO] - Merge complete. Dataframe shape: (23, 5)
2025-10-23 08:46:44 - root - [INFO] - Loading Data...
2025-10-23 08:46:44 - root - [INFO] - Data saved: ../data/merged_data.csv
2025-10-23 08:46:44 - root - [INFO] - Connecting to DB: postgresql+psycopg2://postgres:postgres@postgres:5432/merged_data_db
2025-10-23 08:46:47 - root - [ERROR] - Database load failed: (psycopg2.OperationalError) could not translate host name "postgres" to address: Name or service not known

(Background on this error at: https://sqlalche.me/e/20/e3q8)
Traceback (most recent call last):
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 143, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3301, in raw_connection
    return self.pool.connect()
           ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 447, in connect
    return _ConnectionFairy._checkout(self)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 711, in checkout
    rec = pool._do_get()
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 177, in _do_get
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 175, in _do_get
    return self._create_connection()
           ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 388, in _create_connection
    return _ConnectionRecord(self)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 673, in __init__
    self.__connect()
    ~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 899, in __connect
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 895, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\create.py", line 661, in connect
    return dialect.connect(*cargs, **cparams)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 629, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\psycopg2\__init__.py", line 135, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Name or service not known


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\src\pipeline.py", line 111, in load_to_db
    df.to_sql(db['table'], engine, if_exists='replace', index=False)
    ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\util\_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\core\generic.py", line 3109, in to_sql
    return sql.to_sql(
           ~~~~~~~~~~^
        self,
        ^^^^^
    ...<8 lines>...
        method=method,
        ^^^^^^^^^^^^^^
    )
    ^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\io\sql.py", line 843, in to_sql
    with pandasSQL_builder(con, schema=schema, need_transaction=True) as pandas_sql:
         ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\io\sql.py", line 908, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\pandas\io\sql.py", line 1648, in __init__
    con = self.exit_stack.enter_context(con.connect())
                                        ~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3277, in connect
    return self._connection_cls(self)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 145, in __init__
    Connection._handle_dbapi_exception_noconnection(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        err, dialect, engine
        ^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 2440, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 143, in __init__
    self._dbapi_connection = engine.raw_connection()
                             ~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\base.py", line 3301, in raw_connection
    return self.pool.connect()
           ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 447, in connect
    return _ConnectionFairy._checkout(self)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 1264, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 711, in checkout
    rec = pool._do_get()
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 177, in _do_get
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\impl.py", line 175, in _do_get
    return self._create_connection()
           ~~~~~~~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 388, in _create_connection
    return _ConnectionRecord(self)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 673, in __init__
    self.__connect()
    ~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 899, in __connect
    with util.safe_reraise():
         ~~~~~~~~~~~~~~~~~^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\util\langhelpers.py", line 224, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\pool\base.py", line 895, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\create.py", line 661, in connect
    return dialect.connect(*cargs, **cparams)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\sqlalchemy\engine\default.py", line 629, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "D:\GitHub\Big Data Engineer\ETL Mini Project\.venv\Lib\site-packages\psycopg2\__init__.py", line 135, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Name or service not known

(Background on this error at: https://sqlalche.me/e/20/e3q8)
2025-10-23 08:46:47 - root - [INFO] - ----- Pipeline Execution Completed -----
2025-10-23 08:50:14 - root - [INFO] - Logger initailised from config.
2025-10-23 08:50:14 - root - [INFO] - ----- Pipeline Execution Started -----
2025-10-23 08:50:14 - root - [INFO] - Extracting Data...
2025-10-23 08:50:14 - root - [INFO] - Reading CSV file: ../data/sales.csv
2025-10-23 08:50:14 - root - [INFO] - Reading JSON file: ../data/products.json
2025-10-23 08:50:14 - root - [INFO] - Reading PARQUET file: ../data/region.parquet
2025-10-23 08:50:14 - root - [INFO] - Merging datasets...
2025-10-23 08:50:14 - root - [INFO] - Merge complete. Dataframe shape: (23, 5)
2025-10-23 08:50:14 - root - [INFO] - Loading Data...
2025-10-23 08:50:14 - root - [INFO] - Data saved: ../data/merged_data.csv
2025-10-23 08:50:14 - root - [INFO] - Connecting to DB: postgresql+psycopg2://postgres:postgres@localhost:5432/merged_data_db
2025-10-23 08:50:15 - root - [INFO] - Data successfully loaded into: merged_table
2025-10-23 08:50:15 - root - [INFO] - ----- Pipeline Execution Completed -----
